{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Technical Setup\n",
    "\n"
   ],
   "id": "25397a2bcb1823f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import of Demo Translations\n",
    "In the first step we import the given translations as pandas Dataframes and print a quick overview of the dataframe.\n"
   ],
   "id": "521846f0167f6127"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-26T13:10:27.962649Z",
     "start_time": "2024-12-26T13:10:27.828877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open('machine_translation.pkl', 'rb') as f:\n",
    "    # Einlesen des Dataframes\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpickle\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmachine_translation.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# Einlesen des Dataframes\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\softwarequality\\lib\\site-packages\\pandas\\__init__.py:26\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;66;03m# numpy compat\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     27\u001B[0m         is_numpy_dev \u001B[38;5;28;01mas\u001B[39;00m _is_numpy_dev,  \u001B[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     )\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m _err:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     _module \u001B[38;5;241m=\u001B[39m _err\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\softwarequality\\lib\\site-packages\\pandas\\compat\\__init__.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompressors\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_numpy_dev\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     28\u001B[0m     pa_version_under10p1,\n\u001B[0;32m     29\u001B[0m     pa_version_under11p0,\n\u001B[0;32m     30\u001B[0m     pa_version_under13p0,\n\u001B[0;32m     31\u001B[0m     pa_version_under14p0,\n\u001B[0;32m     32\u001B[0m     pa_version_under14p1,\n\u001B[0;32m     33\u001B[0m     pa_version_under16p0,\n\u001B[0;32m     34\u001B[0m     pa_version_under17p0,\n\u001B[0;32m     35\u001B[0m )\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_typing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m F\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\softwarequality\\lib\\site-packages\\pandas\\compat\\pyarrow.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m     _palv \u001B[38;5;241m=\u001B[39m Version(Version(\u001B[43mpa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__version__\u001B[49m)\u001B[38;5;241m.\u001B[39mbase_version)\n\u001B[0;32m     11\u001B[0m     pa_version_under10p1 \u001B[38;5;241m=\u001B[39m _palv \u001B[38;5;241m<\u001B[39m Version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m10.0.1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m     pa_version_under11p0 \u001B[38;5;241m=\u001B[39m _palv \u001B[38;5;241m<\u001B[39m Version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m11.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'pyarrow' has no attribute '__version__'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import of AI-Models\n",
    "In the second step we import the AI-Models which are given in the specified task. For doing so we use the `llama-cpp-python` library (further documentation can be found [here](https://github.com/abetlen/llama-cpp-python)) and import the models directly from [huggingface](https://huggingface.co/).\n",
    "\n",
    "Quick overview and installation guide of llama.cpp: \n",
    "- https://www.datacamp.com/tutorial/llama-cpp-tutorial\n",
    "- https://christophergs.com/blog/running-open-source-llms-in-python\n",
    "\n"
   ],
   "id": "ed18a088f866a163"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T15:14:16.971594Z",
     "start_time": "2024-12-23T15:14:16.294792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "gemma = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-ai/gemma-2b-it-GGUF\",\n",
    "\tfilename=\"gemma-2b-it-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n"
   ],
   "id": "465e18af3ad7a965",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T15:18:14.843093Z",
     "start_time": "2024-12-23T15:14:29.893432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama32 = Llama.from_pretrained(\n",
    "\trepo_id=\"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\",\n",
    "\tfilename=\"llama-3.2-3b-instruct-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,)\n"
   ],
   "id": "fce7e4c6bc770f24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama-3.2-3b-instruct-q8_0.gguf:   0%|          | 0.00/3.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4440463b74946a3bd7d087181263e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T15:23:28.390956Z",
     "start_time": "2024-12-23T15:18:33.822314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama31 = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "\tfilename=\"Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf\",\n",
    "    verbose=False,)\n"
   ],
   "id": "bf2e6793e18bb549",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf:   0%|          | 0.00/5.73G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54a6dc162a684426a7f9074eb09b0a8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T15:46:45.564877Z",
     "start_time": "2024-12-23T15:24:16.135869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aya23 = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/aya-23-35B-GGUF\",\n",
    "\tfilename=\"aya-23-35B-Q5_K_M.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n"
   ],
   "id": "84de53cf451920f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aya-23-35B-Q5_K_M.gguf:   0%|          | 0.00/25.0G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2c1f1b04b5d4d4b8ae1bed2c33203a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T13:40:48.764083Z",
     "start_time": "2024-12-25T13:40:36.514082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = llama31(\n",
    "\t\"Q: Übersetze mir folgenden Text ins Englische: 'Hallo ich heiße Peter.'\",\n",
    "\tmax_tokens=512,\n",
    "\techo=False,\n",
    "    stop=[\"Q:\"]\n",
    ")\n",
    "\n",
    "# print(output)\n",
    "print(output['choices'][0]['text'])"
   ],
   "id": "f405f223c94046c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Übersetzung: 'Hello my name is Peter.'\n",
      "A: Die richtige Übersetzung ist: 'Hello, my name is Peter.'\n",
      "Hier ist die Erklärung:\n",
      "- 'Hallo' wird 'Hello' übersetzt.\n",
      "- 'Ich heiße' ist 'My name is' gleichbedeutend.\n",
      "- 'Peter' bleibt unverändert, da es nur den Namen bezeichnet. Daher lautet die korrekte Übersetzung: 'Hello, my name is Peter.'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T13:09:52.131477Z",
     "start_time": "2024-12-23T12:58:45.394762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output2 = aya23(\n",
    "\t\"Q: Übersetze mir folgenden Text ins Englische: 'Hallo ich heiße Peter.'\",\n",
    "\tmax_tokens=512,\n",
    "\techo=False,\n",
    "    stop=[\"Q:\"]\n",
    ")\n",
    "\n",
    "# print(output)\n",
    "print(output2['choices'][0]['text'])"
   ],
   "id": "19c424389bdb94a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 'Hello, my name is Peter.'\n",
      "A: Hello, my name is Peter.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:54:30.396745Z",
     "start_time": "2024-12-23T12:20:26.113122Z"
    }
   },
   "cell_type": "code",
   "source": "print(output)",
   "id": "3f2aed159bbfe5d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-e8e08548-44ce-4894-8e4f-024d46a01dfe', 'object': 'text_completion', 'created': 1734956186, 'model': '/Users/fynn/.cache/huggingface/hub/models--lmstudio-community--Meta-Llama-3.1-8B-Instruct-GGUF/snapshots/8601e6db71269a2b12255ebdf09ab75becf22cc8/./Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf', 'choices': [{'text': \" Der Text ist ein Satz.\\nA: Der Übersetzungsversuch wäre: 'Hello, my name is Peter.'\\n\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 22, 'completion_tokens': 28, 'total_tokens': 50}}\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
