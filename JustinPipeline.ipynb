{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompting Pipeline for comparison of different prompting techniques",
   "id": "dc13e903d3aa4223"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import sacrebleu\n",
    "from sacrebleu import corpus_bleu\n",
    "import hashlib\n",
    "from llama_cpp import Llama\n",
    "from sympy import false"
   ],
   "id": "3f0f32f46a65c61e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loading",
   "id": "cfdaa021692ababb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_pickle(\"machine_translation.pkl\")\n",
    "data"
   ],
   "id": "45ac48cddd409ab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_info = pd.DataFrame()\n",
    "data_info['complexity'] = data['complexity']\n",
    "data_info['text_german_length'] = data['text_german'].str.len()\n",
    "data_info['text_english_length'] = data['text_english'].str.len()\n",
    "data_info"
   ],
   "id": "a267ce3ecf138541",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Loading",
   "id": "24e08cf24bbaa6d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Modelle laden\n",
    "gemma = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-ai/gemma-2b-it-GGUF\",\n",
    "\tfilename=\"gemma-2b-it-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "llama32 = Llama.from_pretrained(\n",
    "\trepo_id=\"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\",\n",
    "\tfilename=\"llama-3.2-3b-instruct-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "llama31 = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "\tfilename=\"Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "aya23 = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/aya-23-35B-GGUF\",\n",
    "\tfilename=\"aya-23-35B-Q5_K_M.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "MODELS = {\n",
    "    \"gemma\": gemma,\n",
    "}"
   ],
   "id": "d9c13bd3a8810397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Composition",
   "id": "ecf2526efc0b1eca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Beide Richtungen abbilden: English <-> German\n",
    "# TODO: Verschiedene Prompt Arten: zero-shot, few-shot und verschiedene Variationen reinbringen\n",
    "\n",
    "PROMPT_TEMPLATES_ENGLISH_GERMAN = {\n",
    "    \"zero_shot-english\": \"Please translate the following text from English to German: {text}\",\n",
    "    #\"zero_shot-german\": f\"Bitte übersetze den folgenden Text von Englisch nach Deutsch: {text}\",\n",
    "    #\"few-shot-english-1\": f\"\"\"Please translate a text from English to German.\n",
    "    #Here are some examples:\n",
    "    #- English: \"Hello\" -> German: \"Hallo\"\n",
    "    #- English: \"Goodbye\" -> German: \"Auf Wiedersehen\"\n",
    "    #Now translate this text: {text}\"\"\",\n",
    "    #\"few-shot-german-1\": f\"\"\"Bitte übersetze einen Text von Englisch nach Deutsch.\n",
    "    #Hier sind einige Beispiele:\n",
    "    #- Englisch: \"Hello\" -> Deutsch: \"Hallo\"\n",
    "    #- Englisch: \"Goodbye\" -> Deutsch: \"Auf Wiedersehen\"\n",
    "    #Jetzt übersetze diesen Text: {text}\"\"\",\n",
    "}\n",
    "\n",
    "PROMPT_TEMPLATES_GERMAN_ENGLISH = {\n",
    "    \"zero_shot-english\": \"Please translate the following text from German to English: {text}\",\n",
    "    #\"zero_shot-german\": f\"Bitte übersetze den folgenden Text von Deutsch nach Englisch: {text}\",\n",
    "    #\"few-shot-english-1\": f\"\"\"Please translate a text from German to English.\n",
    "    #Here are some examples:\n",
    "    #- German: \"Hallo\" -> English: \"Hello\"\n",
    "    #- German: \"Auf Wiedersehen\" -> English: \"Goodbye\"\n",
    "    #Now translate this text: {text}\"\"\",\n",
    "    #\"few-shot-german-1\": f\"\"\"Bitte übersetze einen Text von Deutsch nach Englisch.\n",
    "    #Hier sind einige Beispiele:\n",
    "    #- Deutsch: \"Hallo\" -> Englisch: \"Hello\"\n",
    "    #- Deutsch: \"Auf Wiedersehen\" -> Englisch: \"Goodbye\"\n",
    "    #Jetzt übersetze diesen Text: {text}\"\"\",\n",
    "}"
   ],
   "id": "c4fbf0212dbdef82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Interaction",
   "id": "6a0b782490a86ffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:59:29.608639Z",
     "start_time": "2025-01-09T21:59:29.599187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(model, prompt):\n",
    "    response = model(prompt, max_tokens=512, echo=False, stop=[\"Q:\"])\n",
    "    return response['choices'][0]['text']"
   ],
   "id": "cbb082b33b79253d",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "675fddd40f8dceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:59:30.346305Z",
     "start_time": "2025-01-09T21:59:30.343226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_translation(reference, translation):\n",
    "    bleu_score = corpus_bleu([translation], [[reference]]).score\n",
    "    return {\"BLEU\": bleu_score}"
   ],
   "id": "d01c6dcc26865d18",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:59:31.712873Z",
     "start_time": "2025-01-09T21:59:31.708894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def log_to_mlflow(experiment_name, metrics, prompt_type, model_name, complexity):\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "    if experiment:\n",
    "        if experiment.lifecycle_stage == \"deleted\":\n",
    "            mlflow.tracking.MlflowClient().restore_experiment(experiment.experiment_id)\n",
    "            #mlflow.delete_experiment(experiment.experiment_id)\n",
    "    else:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_name=f\"{model_name}/{complexity}/{prompt_type}\"):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_param(\"complexity\", complexity)\n",
    "        mlflow.log_param(\"prompt_type\", prompt_type)\n",
    "        for key, value in metrics.items():\n",
    "            mlflow.log_metric(key, value)"
   ],
   "id": "1fc163f7f59cf98e",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main Pipeline Method",
   "id": "aa9ef32f7b283b8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:59:33.007186Z",
     "start_time": "2025-01-09T21:59:33.001443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_pipeline(texts):\n",
    "    results = pd.DataFrame(columns=[\"model\", \"complexity\", \"prompt_type\", \"prompt\", \"source_text\", \"translation\", \"metrics\"])\n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "    for model_name, model in MODELS.items():\n",
    "        for _, row in texts.iterrows():\n",
    "\n",
    "            # Übersetzung Deutsch -> Englisch\n",
    "            for prompt_type, template in PROMPT_TEMPLATES_GERMAN_ENGLISH.items():\n",
    "                complexity = row['complexity']\n",
    "                if pd.notna(row['text_german']):\n",
    "                    prompt = template.format(text=row['text_german'])\n",
    "                    translation = translate(model, prompt)\n",
    "                    metrics = evaluate_translation(reference=row['text_english'], translation=translation)\n",
    "\n",
    "                    # MLflow-Logging\n",
    "                    experiment_name = f\"{model_name}_{complexity}\"\n",
    "                    log_to_mlflow(experiment_name, metrics, prompt_type, model_name, complexity)\n",
    "\n",
    "                    # Ergebnis speichern\n",
    "                    results = pd.concat([\n",
    "                        results,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": model_name,\n",
    "                            \"complexity\": complexity,\n",
    "                            \"prompt_type\": prompt_type,\n",
    "                            \"prompt\": prompt,\n",
    "                            \"source_text\": row['text_german'],\n",
    "                            \"translation\": translation,\n",
    "                            \"metrics\": metrics\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "                    #results.to_csv(\"results.csv\", index=false)\n",
    "                    #mlflow.log_artifact(\"results.csv\")\n",
    "\n",
    "            # Übersetzung Englisch -> Deutsch\n",
    "            for prompt_type, template in PROMPT_TEMPLATES_ENGLISH_GERMAN.items():\n",
    "                complexity = row['complexity']\n",
    "                if pd.notna(row['text_english']):\n",
    "                    prompt = template.format(text=row['text_english'])\n",
    "                    translation = translate(model, prompt)\n",
    "                    metrics = evaluate_translation(reference=row['text_german'], translation=translation)\n",
    "\n",
    "                    # MLflow-Logging\n",
    "                    experiment_name = f\"{model_name}_{complexity}\"\n",
    "                    log_to_mlflow(experiment_name, metrics, prompt_type, model_name, complexity)\n",
    "\n",
    "                    # Ergebnis speichern\n",
    "                    results = pd.concat([\n",
    "                        results,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": model_name,\n",
    "                            \"complexity\": complexity,\n",
    "                            \"prompt_type\": prompt_type,\n",
    "                            \"prompt\": prompt,\n",
    "                            \"source_text\": row['text_english'],\n",
    "                            \"translation\": translation,\n",
    "                            \"metrics\": metrics\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "                    #results.to_csv(\"results.csv\", index=false)\n",
    "                    #mlflow.log_artifact(\"results.csv\")\n",
    "\n",
    "    return results"
   ],
   "id": "7ef1a149ffa85dcc",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Execute Pipeline",
   "id": "e2b4075d492d5eaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T22:00:13.618888Z",
     "start_time": "2025-01-09T21:59:36.004199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translation_results = run_pipeline(data)\n",
    "translation_results.to_csv(\"translation_results.csv\", index=false)\n",
    "print(\"Pipeline abgeschlossen. Ergebnisse gespeichert.\")"
   ],
   "id": "a5e1f25455f3311b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gemma/easy/zero_shot-english at: http://127.0.0.1:5000/#/experiments/689857147152224931/runs/d04335690e6340d5a7b911e5857eb790\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/689857147152224931\n",
      "🏃 View run gemma/easy/zero_shot-english at: http://127.0.0.1:5000/#/experiments/689857147152224931/runs/a28fde2641af4f9dbd0dd108ff7b5197\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/689857147152224931\n",
      "🏃 View run gemma/news_gen/zero_shot-english at: http://127.0.0.1:5000/#/experiments/795099840311881290/runs/66e672cbc79742cfb9a5cdb9406e90bc\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/795099840311881290\n",
      "🏃 View run gemma/news_gen/zero_shot-english at: http://127.0.0.1:5000/#/experiments/795099840311881290/runs/4db494f07f9945a2b6446e0685e4c323\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/795099840311881290\n",
      "🏃 View run gemma/news_spec/zero_shot-english at: http://127.0.0.1:5000/#/experiments/484847269906363017/runs/210d1afdd3b1496fabde5cba3468026b\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/484847269906363017\n",
      "🏃 View run gemma/news_spec/zero_shot-english at: http://127.0.0.1:5000/#/experiments/484847269906363017/runs/0fa842f12e4443b5893e1e37e1caf3eb\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/484847269906363017\n",
      "🏃 View run gemma/pop_science/zero_shot-english at: http://127.0.0.1:5000/#/experiments/982937374077174631/runs/cd0661ddb4a3499ab06e8b43c963ad3a\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/982937374077174631\n",
      "🏃 View run gemma/pop_science/zero_shot-english at: http://127.0.0.1:5000/#/experiments/982937374077174631/runs/db90437bc6594ba5a0c244647699c20b\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/982937374077174631\n",
      "🏃 View run gemma/science/zero_shot-english at: http://127.0.0.1:5000/#/experiments/164156284498890792/runs/5712ca78ac914b529ed913681b11b5eb\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/164156284498890792\n",
      "🏃 View run gemma/science/zero_shot-english at: http://127.0.0.1:5000/#/experiments/164156284498890792/runs/9b804eb48c7341d9a7cdfe258fc66042\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/164156284498890792\n",
      "Pipeline abgeschlossen. Ergebnisse gespeichert.\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T22:02:12.374492Z",
     "start_time": "2025-01-09T22:02:12.362428Z"
    }
   },
   "cell_type": "code",
   "source": "translation_results",
   "id": "8f4c1b9b3d27fbc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   model   complexity        prompt_type  \\\n",
       "0  gemma         easy  zero_shot-english   \n",
       "1  gemma         easy  zero_shot-english   \n",
       "2  gemma     news_gen  zero_shot-english   \n",
       "3  gemma     news_gen  zero_shot-english   \n",
       "4  gemma    news_spec  zero_shot-english   \n",
       "5  gemma    news_spec  zero_shot-english   \n",
       "6  gemma  pop_science  zero_shot-english   \n",
       "7  gemma  pop_science  zero_shot-english   \n",
       "8  gemma      science  zero_shot-english   \n",
       "9  gemma      science  zero_shot-english   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Please translate the following text from Germa...   \n",
       "1  Please translate the following text from Engli...   \n",
       "2  Please translate the following text from Germa...   \n",
       "3  Please translate the following text from Engli...   \n",
       "4  Please translate the following text from Germa...   \n",
       "5  Please translate the following text from Engli...   \n",
       "6  Please translate the following text from Germa...   \n",
       "7  Please translate the following text from Engli...   \n",
       "8  Please translate the following text from Germa...   \n",
       "9  Please translate the following text from Engli...   \n",
       "\n",
       "                                         source_text  \\\n",
       "0  Felix hat es satt: Ständig ist Mama unterwegs....   \n",
       "1  Felix is fed up: Mom is always on the go. But ...   \n",
       "2  Die rund 1.400 eingesetzten Beamten haben demn...   \n",
       "3  The approximately 1,400 deployed officers have...   \n",
       "4  Der Staatschef hat zugleich aber das Recht, vo...   \n",
       "5  The head of state also has the right to appoin...   \n",
       "6  Dass der Klimawandel die Hitzewellen in Südasi...   \n",
       "7  There is no question that climate change is in...   \n",
       "8  Der DSA-110, der sich am Owens Valley Radio Ob...   \n",
       "9  The DSA-110, situated at the Owens Valley Radi...   \n",
       "\n",
       "                                         translation  \\\n",
       "0                                                      \n",
       "1  \\n\\nIch hoffe, diese Übersetzung ist wie Sie g...   \n",
       "2  \\n\\n**Translation:**\\n\\nApproximately 1.400 em...   \n",
       "3  \\n\\nPlease translate the following text from E...   \n",
       "4                                                      \n",
       "5   This could potentially affect the government'...   \n",
       "6  \\n\\nIn dieser Zeit ist es wichtig, die Rolle v...   \n",
       "7  \\n\\nThe consensus among experts is clear: clim...   \n",
       "8  \\n\\n**English Translation:**\\n\\nThe DSA-110 ra...   \n",
       "9  \\n\\n**Questions:**\\n1. In which observatory is...   \n",
       "\n",
       "                           metrics  \n",
       "0                    {'BLEU': 0.0}  \n",
       "1  {'BLEU': 0.0020445979097311775}  \n",
       "2     {'BLEU': 14.526747499125761}  \n",
       "3     {'BLEU': 0.7860561859628806}  \n",
       "4                    {'BLEU': 0.0}  \n",
       "5     {'BLEU': 0.6057232211712502}  \n",
       "6     {'BLEU': 1.9084912671852643}  \n",
       "7    {'BLEU': 0.11276930404887484}  \n",
       "8     {'BLEU': 41.601423151567076}  \n",
       "9     {'BLEU': 3.5886176944270933}  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>complexity</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>source_text</th>\n",
       "      <th>translation</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>easy</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Germa...</td>\n",
       "      <td>Felix hat es satt: Ständig ist Mama unterwegs....</td>\n",
       "      <td></td>\n",
       "      <td>{'BLEU': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma</td>\n",
       "      <td>easy</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Engli...</td>\n",
       "      <td>Felix is fed up: Mom is always on the go. But ...</td>\n",
       "      <td>\\n\\nIch hoffe, diese Übersetzung ist wie Sie g...</td>\n",
       "      <td>{'BLEU': 0.0020445979097311775}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma</td>\n",
       "      <td>news_gen</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Germa...</td>\n",
       "      <td>Die rund 1.400 eingesetzten Beamten haben demn...</td>\n",
       "      <td>\\n\\n**Translation:**\\n\\nApproximately 1.400 em...</td>\n",
       "      <td>{'BLEU': 14.526747499125761}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma</td>\n",
       "      <td>news_gen</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Engli...</td>\n",
       "      <td>The approximately 1,400 deployed officers have...</td>\n",
       "      <td>\\n\\nPlease translate the following text from E...</td>\n",
       "      <td>{'BLEU': 0.7860561859628806}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma</td>\n",
       "      <td>news_spec</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Germa...</td>\n",
       "      <td>Der Staatschef hat zugleich aber das Recht, vo...</td>\n",
       "      <td></td>\n",
       "      <td>{'BLEU': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemma</td>\n",
       "      <td>news_spec</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Engli...</td>\n",
       "      <td>The head of state also has the right to appoin...</td>\n",
       "      <td>This could potentially affect the government'...</td>\n",
       "      <td>{'BLEU': 0.6057232211712502}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemma</td>\n",
       "      <td>pop_science</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Germa...</td>\n",
       "      <td>Dass der Klimawandel die Hitzewellen in Südasi...</td>\n",
       "      <td>\\n\\nIn dieser Zeit ist es wichtig, die Rolle v...</td>\n",
       "      <td>{'BLEU': 1.9084912671852643}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemma</td>\n",
       "      <td>pop_science</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Engli...</td>\n",
       "      <td>There is no question that climate change is in...</td>\n",
       "      <td>\\n\\nThe consensus among experts is clear: clim...</td>\n",
       "      <td>{'BLEU': 0.11276930404887484}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemma</td>\n",
       "      <td>science</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Germa...</td>\n",
       "      <td>Der DSA-110, der sich am Owens Valley Radio Ob...</td>\n",
       "      <td>\\n\\n**English Translation:**\\n\\nThe DSA-110 ra...</td>\n",
       "      <td>{'BLEU': 41.601423151567076}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemma</td>\n",
       "      <td>science</td>\n",
       "      <td>zero_shot-english</td>\n",
       "      <td>Please translate the following text from Engli...</td>\n",
       "      <td>The DSA-110, situated at the Owens Valley Radi...</td>\n",
       "      <td>\\n\\n**Questions:**\\n1. In which observatory is...</td>\n",
       "      <td>{'BLEU': 3.5886176944270933}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:57:09.478287Z",
     "start_time": "2025-01-09T21:57:09.475446Z"
    }
   },
   "cell_type": "code",
   "source": "mlflow.end_run()",
   "id": "12161ce377307c70",
   "outputs": [],
   "execution_count": 85
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
