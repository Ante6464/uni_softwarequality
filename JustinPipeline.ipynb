{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompting Pipeline for comparison of different prompting techniques",
   "id": "7168eea69cea0132"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T21:36:54.876331Z",
     "start_time": "2025-01-07T21:36:54.867260Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import sacrebleu\n",
    "import hashlib\n",
    "from llama_cpp import Llama"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loading",
   "id": "c9652180add38161"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T21:36:57.131511Z",
     "start_time": "2025-01-07T21:36:57.124383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_pickle(\"machine_translation.pkl\")\n",
    "data"
   ],
   "id": "8499598514c4a0c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    complexity                                        text_german  \\\n",
       "0         easy  Felix hat es satt: Ständig ist Mama unterwegs....   \n",
       "1     news_gen  Die rund 1.400 eingesetzten Beamten haben demn...   \n",
       "2    news_spec  Der Staatschef hat zugleich aber das Recht, vo...   \n",
       "3  pop_science  Dass der Klimawandel die Hitzewellen in Südasi...   \n",
       "4      science  Der DSA-110, der sich am Owens Valley Radio Ob...   \n",
       "\n",
       "                                        text_english  \n",
       "0  Felix is fed up: Mom is always on the go. But ...  \n",
       "1  The approximately 1,400 deployed officers have...  \n",
       "2  The head of state also has the right to appoin...  \n",
       "3  There is no question that climate change is in...  \n",
       "4  The DSA-110, situated at the Owens Valley Radi...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>text_german</th>\n",
       "      <th>text_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easy</td>\n",
       "      <td>Felix hat es satt: Ständig ist Mama unterwegs....</td>\n",
       "      <td>Felix is fed up: Mom is always on the go. But ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_gen</td>\n",
       "      <td>Die rund 1.400 eingesetzten Beamten haben demn...</td>\n",
       "      <td>The approximately 1,400 deployed officers have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news_spec</td>\n",
       "      <td>Der Staatschef hat zugleich aber das Recht, vo...</td>\n",
       "      <td>The head of state also has the right to appoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop_science</td>\n",
       "      <td>Dass der Klimawandel die Hitzewellen in Südasi...</td>\n",
       "      <td>There is no question that climate change is in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>Der DSA-110, der sich am Owens Valley Radio Ob...</td>\n",
       "      <td>The DSA-110, situated at the Owens Valley Radi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T21:36:58.440258Z",
     "start_time": "2025-01-07T21:36:58.431326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_info = pd.DataFrame()\n",
    "data_info['complexity'] = data['complexity']\n",
    "data_info['text_german_length'] = data['text_german'].str.len()\n",
    "data_info['text_english_length'] = data['text_english'].str.len()\n",
    "data_info"
   ],
   "id": "f1524b7507e07a6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    complexity  text_german_length  text_english_length\n",
       "0         easy                 485                  415\n",
       "1     news_gen                 296                  280\n",
       "2    news_spec                 518                  484\n",
       "3  pop_science                 542                  521\n",
       "4      science                1003                  827"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>text_german_length</th>\n",
       "      <th>text_english_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easy</td>\n",
       "      <td>485</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_gen</td>\n",
       "      <td>296</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news_spec</td>\n",
       "      <td>518</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop_science</td>\n",
       "      <td>542</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>1003</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Composition",
   "id": "6702e4d93a1af634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Beide Richtungen abbilden: English <-> German\n",
    "# TODO: Verschiedene Prompt Arten: zero-shot, few-shot und verschiedene Variationen reinbringen\n",
    "\n",
    "prompts = []\n",
    "for _, row in data.iterrows():\n",
    "    text = row['text_english']\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    prompt = f\"Please translate the following English text to German: {cleaned_text}\"\n",
    "    prompts.append(prompt)\n",
    "data['prompt'] = prompts"
   ],
   "id": "4f34cc94cb7c888f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Interaction",
   "id": "37deefa358457988"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Modelle laden\n",
    "gemma = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-ai/gemma-2b-it-GGUF\",\n",
    "\tfilename=\"gemma-2b-it-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "llama32 = Llama.from_pretrained(\n",
    "\trepo_id=\"hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF\",\n",
    "\tfilename=\"llama-3.2-3b-instruct-q8_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "llama31 = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "\tfilename=\"Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "aya23 = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/aya-23-35B-GGUF\",\n",
    "\tfilename=\"aya-23-35B-Q5_K_M.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    ")"
   ],
   "id": "70ea73c439271270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "ef5798fe874d276f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2b07d83fbb232efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Übersetzungen mit llama.cpp durchführen\n",
    "def translate_with_llama(data):\n",
    "    translations = []\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Translation with llama.cpp\"):\n",
    "        mlflow.log_param(\"model\", \"gemma-2b-it-GGUF\")\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            prompt = row['prompt']\n",
    "            response = gemma(prompt, max_tokens=512, echo=False, stop=[\"Q:\"])\n",
    "            translated_text = response['choices'][0]['text']\n",
    "\n",
    "            # Metriken loggen\n",
    "            mlflow.log_metric(f\"translation_length_{index}\", len(translated_text))\n",
    "\n",
    "            # Generate a unique filename for logging, using a hash of the prompt\n",
    "            prompt_hash = hashlib.md5(prompt.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            translated_text_hash = hashlib.md5(translated_text.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            mlflow.log_text(f\"Prompt_{index}\", prompt_hash)\n",
    "            mlflow.log_text(f\"Translation_{index}\", translated_text_hash)\n",
    "\n",
    "            translations.append(translated_text)\n",
    "\n",
    "        # Ergebnisse als Artefakt speichern\n",
    "        data['translation'] = translations\n",
    "        data.to_csv(\"translations.csv\", index=False)\n",
    "        mlflow.log_artifact(\"translations.csv\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Hauptpipeline\n",
    "def main_pipeline():\n",
    "    # Daten laden\n",
    "    data = load_data()\n",
    "    print(\"Daten geladen.\")\n",
    "\n",
    "    # Prompts erstellen\n",
    "    data = generate_prompts(data)\n",
    "    print(\"Prompts erstellt.\")\n",
    "\n",
    "    # Übersetzungen durchführen\n",
    "    data = translate_with_llama(data)\n",
    "    print(\"Übersetzungen durchgeführt.\")\n",
    "\n",
    "    # Ergebnisse speichern\n",
    "    output_path = \"translated_results.csv\"\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Ergebnisse gespeichert: {output_path}\")\n",
    "\n",
    "# Ausführung\n",
    "experiment_name = \"Pipeline_FirstTest\"\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "gemma = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-ai/gemma-2b-it-GGUF\",\n",
    "\tfilename=\"gemma-2b-it-q8_0.gguf\",\n",
    "    echo=False,\n",
    "    stop=[\"Q:\"],\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    "    )\n",
    "\n",
    "main_pipeline()"
   ],
   "id": "a67611a4940149cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
