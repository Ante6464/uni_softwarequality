{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prompting Pipeline for comparison of different prompting techniques",
   "id": "7168eea69cea0132"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T12:50:47.990471Z",
     "start_time": "2025-01-04T12:50:45.246420Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import sacrebleu"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Loading",
   "id": "c9652180add38161"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T12:23:27.100337Z",
     "start_time": "2024-12-27T12:23:27.071225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Daten laden\n",
    "text = pd.read_pickle('machine_translation.pkl')\n",
    "text\n",
    "\n",
    "# Standardisierung ?"
   ],
   "id": "8499598514c4a0c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    complexity                                        text_german  \\\n",
       "0         easy  Felix hat es satt: St√§ndig ist Mama unterwegs....   \n",
       "1     news_gen  Die rund 1.400 eingesetzten Beamten haben demn...   \n",
       "2    news_spec  Der Staatschef hat zugleich aber das Recht, vo...   \n",
       "3  pop_science  Dass der Klimawandel die Hitzewellen in S√ºdasi...   \n",
       "4      science  Der DSA-110, der sich am Owens Valley Radio Ob...   \n",
       "\n",
       "                                        text_english  \n",
       "0  Felix is fed up: Mom is always on the go. But ...  \n",
       "1  The approximately 1,400 deployed officers have...  \n",
       "2  The head of state also has the right to appoin...  \n",
       "3  There is no question that climate change is in...  \n",
       "4  The DSA-110, situated at the Owens Valley Radi...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>text_german</th>\n",
       "      <th>text_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easy</td>\n",
       "      <td>Felix hat es satt: St√§ndig ist Mama unterwegs....</td>\n",
       "      <td>Felix is fed up: Mom is always on the go. But ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news_gen</td>\n",
       "      <td>Die rund 1.400 eingesetzten Beamten haben demn...</td>\n",
       "      <td>The approximately 1,400 deployed officers have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news_spec</td>\n",
       "      <td>Der Staatschef hat zugleich aber das Recht, vo...</td>\n",
       "      <td>The head of state also has the right to appoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pop_science</td>\n",
       "      <td>Dass der Klimawandel die Hitzewellen in S√ºdasi...</td>\n",
       "      <td>There is no question that climate change is in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>Der DSA-110, der sich am Owens Valley Radio Ob...</td>\n",
       "      <td>The DSA-110, situated at the Owens Valley Radi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Composition",
   "id": "6702e4d93a1af634"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_prompt(text, mode=\"zero-shot\"):\n",
    "    if mode == \"zero-shot\":\n",
    "        return f\"Translate this text into German: {text}\"\n",
    "    elif mode == \"few-shot\":\n",
    "        examples = \"Example 1: Hello -> Hallo\\nExample 2: Goodbye -> Auf Wiedersehen\\n\"\n",
    "        return f\"{examples}Translate this text into German: {text}\""
   ],
   "id": "4f34cc94cb7c888f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Interaction",
   "id": "37deefa358457988"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Modell laden\n",
    "translation_model = pipeline(\"translation_en_to_de\", model=\"lmstudio-ai/gemma-2b-it-GGUF\")\n",
    "\n",
    "# Prompt senden und Ergebnisse sammeln\n",
    "def translate_text(prompt):\n",
    "    result = translation_model(prompt)\n",
    "    return result[0][\"translation_text\"]"
   ],
   "id": "70ea73c439271270"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "ef5798fe874d276f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b07d83fbb232efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T12:54:53.839650Z",
     "start_time": "2025-01-04T12:54:14.392840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Daten laden\n",
    "def load_data():\n",
    "    data = pd.read_pickle(\"machine_translation.pkl\")\n",
    "    return data\n",
    "\n",
    "# Prompts erstellen\n",
    "def generate_prompts(data):\n",
    "    prompts = []\n",
    "    for _, row in data.iterrows():\n",
    "        text = row['text_english']\n",
    "        cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "        prompt = f\"Translate the following text to German: {cleaned_text}\"\n",
    "        prompts.append(prompt)\n",
    "    data['prompt'] = prompts\n",
    "    return data\n",
    "\n",
    "# √úbersetzungen mit llama.cpp durchf√ºhren\n",
    "def translate_with_llama(data):\n",
    "    translations = []\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Translation with llama.cpp\"):\n",
    "        mlflow.log_param(\"model\", \"gemma-2b-it-GGUF\")\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            prompt = row['prompt']\n",
    "            response = gemma(prompt, max_tokens=512, echo=False, stop=[\"Q:\"])\n",
    "            translated_text = response['choices'][0]['text']\n",
    "\n",
    "            # Metriken loggen\n",
    "            mlflow.log_metric(f\"translation_length_{index}\", len(translated_text))\n",
    "\n",
    "            # Generate a unique filename for logging, using a hash of the prompt\n",
    "            prompt_hash = hashlib.md5(prompt.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            translated_text_hash = hashlib.md5(translated_text.encode(\"utf-8\")).hexdigest()[:8]\n",
    "            mlflow.log_text(f\"Prompt_{index}\", prompt_hash)\n",
    "            mlflow.log_text(f\"Translation_{index}\", translated_text_hash)\n",
    "\n",
    "            translations.append(translated_text)\n",
    "\n",
    "        # Ergebnisse als Artefakt speichern\n",
    "        data['translation'] = translations\n",
    "        data.to_csv(\"translations.csv\", index=False)\n",
    "        mlflow.log_artifact(\"translations.csv\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Hauptpipeline\n",
    "def main_pipeline():\n",
    "    # Daten laden\n",
    "    data = load_data()\n",
    "    print(\"Daten geladen.\")\n",
    "\n",
    "    # Prompts erstellen\n",
    "    data = generate_prompts(data)\n",
    "    print(\"Prompts erstellt.\")\n",
    "\n",
    "    # √úbersetzungen durchf√ºhren\n",
    "    data = translate_with_llama(data)\n",
    "    print(\"√úbersetzungen durchgef√ºhrt.\")\n",
    "\n",
    "    # Ergebnisse speichern\n",
    "    output_path = \"translated_results.csv\"\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Ergebnisse gespeichert: {output_path}\")\n",
    "\n",
    "# Ausf√ºhrung\n",
    "experiment_name = \"Pipeline_FirstTest\"\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "gemma = Llama.from_pretrained(\n",
    "\trepo_id=\"lmstudio-ai/gemma-2b-it-GGUF\",\n",
    "\tfilename=\"gemma-2b-it-q8_0.gguf\",\n",
    "    echo=False,\n",
    "    stop=[\"Q:\"],\n",
    "    n_gpu_layers=1,\n",
    "    verbose=False,\n",
    "    )\n",
    "\n",
    "main_pipeline()"
   ],
   "id": "a67611a4940149cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten geladen.\n",
      "Prompts erstellt.\n",
      "üèÉ View run Translation with llama.cpp at: http://127.0.0.1:5000/#/experiments/227834415347659719/runs/5aca6312e6d24af8a7239327286fbd4d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/227834415347659719\n",
      "√úbersetzungen durchgef√ºhrt.\n",
      "Ergebnisse gespeichert: translated_results.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
